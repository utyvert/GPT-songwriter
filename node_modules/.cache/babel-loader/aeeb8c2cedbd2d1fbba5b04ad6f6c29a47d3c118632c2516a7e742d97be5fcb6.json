{"ast":null,"code":"// import axios from 'axios';\n\n// const API_KEY = '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';\n// const API_URL = 'https://api.openai.com/v1/completions';\n\n// export async function GPT3(prompt) {\n//   try {\n//     const response = await axios.post(API_URL, {\n//       prompt: prompt,\n//       max_tokens: 256,\n//       n: 1,\n//       temperature: 0.7,\n//       api_key: API_KEY,\n//     });\n\n//     const generatedText = response.data.choices[0].text;\n//     return generatedText;\n//   } catch (error) {\n//     console.error(error);\n//   }\n// }\n\nconst openai = require('openai');\n\n// Configure the OpenAI client with your API key\nopenai.apiKey = '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';\n\n// Define the GPT3 function to generate text completions\nfunction GPT3(prompt, temperature) {\n  // Use the 'completions' endpoint to generate text completions\n  openai.completions.create({\n    // Provide the model ID and the prompt to complete\n    model: 'text-completion-002',\n    prompt: prompt,\n    temperature: temperature\n  }, (err, response) => {\n    // Handle any errors\n    if (err) {\n      console.error(err);\n      return;\n    }\n\n    // Print the generated completions to the console\n    console.log(response.data.choices[0].text);\n  });\n}\n\n// Call the GPT3 function with a prompt and temperature value\n_c = GPT3;\nGPT3('The quick brown fox jumps over the lazy ', 0.5);\nvar _c;\n$RefreshReg$(_c, \"GPT3\");","map":{"version":3,"names":["openai","require","apiKey","GPT3","prompt","temperature","completions","create","model","err","response","console","error","log","data","choices","text"],"sources":["/Users/utkarshuppal/Documents/GitHub/GPT-songwriter/src/components/GPT3.js"],"sourcesContent":["// import axios from 'axios';\n\n// const API_KEY = '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';\n// const API_URL = 'https://api.openai.com/v1/completions';\n\n// export async function GPT3(prompt) {\n//   try {\n//     const response = await axios.post(API_URL, {\n//       prompt: prompt,\n//       max_tokens: 256,\n//       n: 1,\n//       temperature: 0.7,\n//       api_key: API_KEY,\n//     });\n\n//     const generatedText = response.data.choices[0].text;\n//     return generatedText;\n//   } catch (error) {\n//     console.error(error);\n//   }\n// }\n\nconst openai = require('openai');\n\n// Configure the OpenAI client with your API key\nopenai.apiKey = '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';\n\n// Define the GPT3 function to generate text completions\nfunction GPT3(prompt, temperature) {\n  // Use the 'completions' endpoint to generate text completions\n  openai.completions.create(\n    {\n      // Provide the model ID and the prompt to complete\n      model: 'text-completion-002',\n      prompt: prompt,\n      temperature: temperature\n    },\n    (err, response) => {\n      // Handle any errors\n      if (err) {\n        console.error(err);\n        return;\n      }\n\n      // Print the generated completions to the console\n      console.log(response.data.choices[0].text);\n    }\n  );\n}\n\n// Call the GPT3 function with a prompt and temperature value\nGPT3('The quick brown fox jumps over the lazy ', 0.5);\n"],"mappings":"AAAA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,MAAMA,MAAM,GAAGC,OAAO,CAAC,QAAQ,CAAC;;AAEhC;AACAD,MAAM,CAACE,MAAM,GAAG,qDAAqD;;AAErE;AACA,SAASC,IAAI,CAACC,MAAM,EAAEC,WAAW,EAAE;EACjC;EACAL,MAAM,CAACM,WAAW,CAACC,MAAM,CACvB;IACE;IACAC,KAAK,EAAE,qBAAqB;IAC5BJ,MAAM,EAAEA,MAAM;IACdC,WAAW,EAAEA;EACf,CAAC,EACD,CAACI,GAAG,EAAEC,QAAQ,KAAK;IACjB;IACA,IAAID,GAAG,EAAE;MACPE,OAAO,CAACC,KAAK,CAACH,GAAG,CAAC;MAClB;IACF;;IAEA;IACAE,OAAO,CAACE,GAAG,CAACH,QAAQ,CAACI,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACC,IAAI,CAAC;EAC5C,CAAC,CACF;AACH;;AAEA;AAAA,KAtBSb,IAAI;AAuBbA,IAAI,CAAC,0CAA0C,EAAE,GAAG,CAAC;AAAC;AAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}